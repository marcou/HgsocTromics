{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare factors delivered by the three methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "% matplotlib inline\n",
    "from sklearn.manifold import TSNE \n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorizer classes\n",
    "These have now been hived off into ``factorizer_wrappers.py``.  Import and test them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from factorizer_wrappers import ICA_Factorizer, NMF_Factorizer, PCA_Factorizer\n",
    "from factorizer_wrappers import example_V, test_example_V, test_Factorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_example_V()\n",
    "\n",
    "test_Factorizer(ICA_Factorizer(n_components=4, fun='cube', algorithm='parallel'), atol=0.5) \n",
    "test_Factorizer(ICA_Factorizer(n_components=5), atol=0.001) \n",
    "\n",
    "test_Factorizer(NMF_Factorizer(n_components=4, max_iter=1000), atol=0.5) \n",
    "test_Factorizer(NMF_Factorizer(n_components=5, max_iter=1000), atol=0.1) \n",
    "\n",
    "test_Factorizer(PCA_Factorizer(n_components=4), atol=0.5) \n",
    "test_Factorizer(PCA_Factorizer(n_components=5), atol=0.001) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the expression matrix\n",
    "This is repeated code, should be factored out..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in expression spreadsheet which has been processed (see end of notebook) to inlcude only protein coding genes\n",
    "expression_df = pd.read_csv('../Data/HGSOC_Protein_Expression.csv', sep='\\t')\n",
    "expression_df.set_index('GeneENSG', inplace=True)\n",
    "assert len(expression_df) == 19730   # Only \n",
    "assert len(expression_df.columns) == 80\n",
    "assert expression_df.columns[-1] == 'AOCS_171'\n",
    "expression_matrix = normalize(np.asarray(expression_df))\n",
    "\n",
    "print(expression_matrix.shape[0], \"genes\")\n",
    "print(expression_matrix.shape[1], \"patients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_norm_diff(m1, m2):\n",
    "    return np.sqrt(np.mean((m1 - m2)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(v1, v2):\n",
    "    dotp = np.dot(v1, v2)\n",
    "    v1_mag = np.sqrt(np.sum(v1 * v1))\n",
    "    v2_mag = np.sqrt(np.sum(v2 * v2))\n",
    "    costheta = dotp / (v1_mag * v2_mag)\n",
    "    \n",
    "    angleRad = np.arccos(abs(min(costheta, 1.0)))\n",
    "    angleDeg = angleRad * (180 / np.pi)\n",
    "    return angleDeg\n",
    "\n",
    "(distance(np.array([1,0,0,1]), np.array([1,0,0,1])), \n",
    " distance(np.array([1,0,0,1]), np.array([0,0,0,1])),\n",
    " distance(np.array([1,0,0,0]), np.array([0,0,0,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Angle calculation\n",
    "\n",
    "def calc_angle(v1, v2, show=False):\n",
    "    \n",
    "    dotp = np.dot(v1, v2)\n",
    "    v1_mag = np.sqrt(np.sum(v1 * v1))\n",
    "    v2_mag = np.sqrt(np.sum(v2 * v2))\n",
    "    costheta = dotp / (v1_mag * v2_mag)\n",
    "\n",
    "    angleRad = np.arccos(min(costheta, 1.0))\n",
    "    angleDeg = angleRad * (180 / np.pi)\n",
    "\n",
    "    if show:\n",
    "        print (\"v1:\\n\")\n",
    "        print (v1)\n",
    "        print (\"\\nv2:\")\n",
    "        print (v2)\n",
    "        print (\"\\nv1 Mag.:%6.4f\" % v1_mag)\n",
    "        print (\"\\nv2 Mag.:%6.4f\" % v2_mag)\n",
    "        print (\"v1 . v2 = %6.4f\" % dotp)\n",
    "        print(dotp / (m1_mag * m2_mag))\n",
    "        print (\"Angle between v1 and v2 = %5.1f degrees.\" % angleDeg)\n",
    "    return angleDeg\n",
    "\n",
    "calc_angle(v1= np.array([0,0,0,1]), v2=np.array([1,1,1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Angle of vectors in a high dimensined space\n",
    "Demonstrating that in a 20,000 dimensioned space, any two random vectors will be at very close to 90 degrees!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alist = []\n",
    "dims=20000\n",
    "n=5000\n",
    "rvs = np.random.randn(n, dims)\n",
    "for i in range(n-1):\n",
    "    v1 = rvs[i,:]\n",
    "    v2 = rvs[i+1,:]\n",
    "    a = calc_angle(v1,v2)\n",
    "    alist += [a]\n",
    "    \n",
    "plt.hist(alist, bins=50)\n",
    "plt.title(\"Mean=%6.2f, SD=%6.2f degrees\" % (np.mean(alist), np.std(alist)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple cached runs of NMF and ICA\n",
    "Run NMF and ICA for a range of components, with repeats and save into .pkl fles for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(V, facto_class, n_components, n_repeats):\n",
    "    pickle_fname = \"../Cache/FactorizerExpt/%s_%d_%d.pkl\" % (facto_class.__name__, n_components, n_repeats)\n",
    "    print(pickle_fname)\n",
    "    metagene_list = []\n",
    "    for i in range(n_repeats):\n",
    "        facto = facto_class(n_components=n_components, max_iter=5000, random_state=np.random.randint(10000))\n",
    "        facto.fit(V)\n",
    "        metagene_list += [facto.get_W()]\n",
    "        print('\\r%d/%d' % (i+1, n_repeats), end='')\n",
    "    print()\n",
    "    with open(pickle_fname, 'wb') as f:\n",
    "        pickle.dump(metagene_list, f)\n",
    "        \n",
    "run(expression_matrix, ICA_Factorizer, 4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will take several hours, if enabled! \n",
    "if False:\n",
    "    for nc in range(2, 31):\n",
    "        run(expression_matrix, NMF_Factorizer, nc, 50)\n",
    "        run(expression_matrix, ICA_Factorizer, nc, 50)\n",
    "        print()\n",
    "\n",
    "    print(\"All Done.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE plots of NMF, ICA and PCA components\n",
    "It's interesting to see the components generated by the three methods ploted in the same space.   However, we must beware of over-interpeting t-SNE plots..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_factors_scatter(n_components, n_repeats):\n",
    "    \n",
    "    # Read back the pickle files containing multiple runs. One file for each n_components for each\n",
    "    # of NMF and ICA\n",
    "    \n",
    "    dummy_facto = NMF_Factorizer()\n",
    "    pickle_fname = \"../Cache/FactorizerExpt/%s_%d_%d.pkl\" % (type(dummy_facto).__name__, n_components, n_repeats)\n",
    "    # print(pickle_fname)\n",
    "    with open(pickle_fname, 'rb') as f:\n",
    "        nmf_metagene_list = pickle.load(f)\n",
    "\n",
    "    dummy_facto = ICA_Factorizer()\n",
    "    pickle_fname = \"../Cache/FactorizerExpt/%s_%d_%d.pkl\" % (type(dummy_facto).__name__, n_components, n_repeats)\n",
    "    with open(pickle_fname, 'rb') as f:\n",
    "        ica_metagene_list = pickle.load(f)\n",
    "        \n",
    "    # Add result of PCA analysis for same number of components\n",
    "    pca_facto = PCA_Factorizer(n_components=n_components)\n",
    "    pca_facto.fit(expression_matrix)\n",
    "    pca_metagenes = pca_facto.get_W()\n",
    "    \n",
    "    stacked_metagenes = np.hstack(nmf_metagene_list + ica_metagene_list + [pca_metagenes]).T\n",
    "    \n",
    "    # For ICA at least, we see double the expected number of components, due to the arbitrary direction of the vector\n",
    "    # So flip them into the same overall direction\n",
    "    flipped_metagenes = [g if sum(g[:10])>0 else -g for g in stacked_metagenes[:]]\n",
    "\n",
    "    # Reduce to a managable number of dimensions before passing to t-SNE\n",
    "    pca = PCA(n_components=50)\n",
    "    tsne = TSNE(n_components=2, init='pca', n_jobs=7)\n",
    "    Y = tsne.fit_transform(pca.fit_transform(flipped_metagenes))\n",
    "    Y.shape\n",
    "\n",
    "    \n",
    "    # Plot the t-SNE projections in two halves so that NMF and ICA show in different colours\n",
    "    assert Y.shape[0] == 2 * n_components * n_repeats + n_components\n",
    "    # Start indices of the components in Y\n",
    "    nmf_Y = Y[0:n_components * n_repeats, :]\n",
    "    ica_Y = Y[n_components * n_repeats: 2 * n_components * n_repeats, :]\n",
    "    pca_Y = Y[2 * n_components * n_repeats:, :]\n",
    "    \n",
    "    plt.scatter(nmf_Y[:,0], nmf_Y[:,1], s=3, label='NMF')\n",
    "    plt.scatter(ica_Y[:,0], ica_Y[:,1], s=3, label='ICA')\n",
    "    plt.scatter(pca_Y[:,0], pca_Y[:,1], s=50, marker = '+', label='PCA')\n",
    "    \n",
    "    plt.xlabel(\"t-SNE dimension 1\")\n",
    "    plt.ylabel(\"t-SNE dimension 2\")\n",
    "    ax = plt.gca()\n",
    "    ax.axes.xaxis.set_visible(False)\n",
    "    ax.axes.yaxis.set_visible(False)\n",
    "    \n",
    "    \n",
    "    plt.legend()\n",
    "    plt.title(\"Components: %d\" % n_components)\n",
    "    \n",
    "plt.figure(figsize=(4,4))\n",
    "combined_factors_scatter(3, 50)\n",
    "plt.suptitle(\"Just testing...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_combined_factors_scatter(start_comp, end_comp):\n",
    "    plt.figure(figsize=(16,20))\n",
    "    # plt.figure(figsize=(8,8))\n",
    "\n",
    "    n_repeats = 50\n",
    "    for nc in range(start_comp, end_comp):\n",
    "        print('.', end='')\n",
    "        plt.subplot(4,3,nc-start_comp+1)\n",
    "        combined_factors_scatter(nc, n_repeats)\n",
    "    plt.suptitle(\"t-SNE clustering for %d repeats of NMF and ICA\", size=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_multiple_combined_factors_scatter(3, 15)\n",
    "plot_multiple_combined_factors_scatter(16, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick out the clusters with k-means\n",
    "Although NMF seems to preduce components in a repeatable order - so that centroids can be calculated\n",
    "directly, this seems not to be the case for ICA.  So use k-means to sort them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def investigate_cluster_statistics(facto, doprint=False):\n",
    "    # The given facto is not actually executed, just used to select the appropriate cached\n",
    "    # .pkl files which were computed above.\n",
    "    n_repeats = 50\n",
    "    n_components = facto.n_components\n",
    "    pickle_fname = \"../Cache/FactorizerExpt/%s_%d_%d.pkl\" % (type(facto).__name__, n_components, n_repeats)\n",
    "    # print(pickle_fname)\n",
    "    with open(pickle_fname, 'rb') as f:\n",
    "        metagene_list = pickle.load(f)\n",
    "    stacked_metagenes = np.hstack(metagene_list).T\n",
    "    flipped_metagenes = [g if sum(g[:10])>0 else -g for g in stacked_metagenes[:]]\n",
    "\n",
    "    pca = PCA(n_components=10)\n",
    "    kmeans = KMeans(n_clusters=n_components, random_state=0).fit(pca.fit_transform(flipped_metagenes))\n",
    "    cluster_table = np.reshape(kmeans.labels_, (n_repeats, n_components))\n",
    "    clusters_are_aligned = np.all([cluster_table[r,:] == cluster_table[0,:] for r in range(n_repeats)])\n",
    "    if doprint:\n",
    "        for r in range(n_repeats):\n",
    "            print(r, cluster_table[r,:])\n",
    "        print()\n",
    "    return clusters_are_aligned\n",
    "    \n",
    "\n",
    "investigate_cluster_statistics(NMF_Factorizer(n_components=4), True)\n",
    "investigate_cluster_statistics(ICA_Factorizer(n_components=4), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see if clusters are assined consistently for NMF and ICA across a range of n_components\n",
    "print(\"%6s %10s %10s\" % ('', NMF_Factorizer.__name__, ICA_Factorizer.__name__))\n",
    "for nc in range(3,31):\n",
    "    nmf_consistent = investigate_cluster_statistics(NMF_Factorizer(n_components=nc))\n",
    "    ica_consistent = investigate_cluster_statistics(ICA_Factorizer(n_components=nc))\n",
    "    print(\"%6d%10s %10s\" % (nc, nmf_consistent, ica_consistent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS BROKEN!\n",
    "# Calculate angles between components\n",
    "a = pca.inverse_transform(kmeans.cluster_centers_)\n",
    "n = a.shape[0]\n",
    "angle_matrix=np.zeros((n,n))\n",
    "for i1 in range(n):\n",
    "    for i2 in range(n):\n",
    "        v1, v2 = a[i1,:], a[i2,:]\n",
    "        angle_matrix[i1, i2] = calc_angle(v1, v2)\n",
    "\n",
    "for i1 in range(n):\n",
    "    print(\"%2d: \" % i1, end=\"\")\n",
    "    for i2 in range(n):\n",
    "        if (i2 <= i1):\n",
    "            print(\"%6.0f°\" % angle_matrix[i1, i2], end=\"\")\n",
    "    print()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
