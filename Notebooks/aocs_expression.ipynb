{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying ICA / NMF to AOCS Ovarian Cancer gene expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import NMF, FastICA, PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import statsmodels.formula.api as sm\n",
    "import pickle\n",
    "import mygene\n",
    "import qgrid\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='white', context='notebook', rc={'figure.figsize':(10,6)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_V(n_genes=100):\n",
    "    # Generate example expression matrix, useful in tests\n",
    "    np.random.seed(0)\n",
    "    time = np.linspace(0, 8, n_genes)\n",
    "\n",
    "    s1 = np.sin(time) + 1.1  # Signal 1 : sinusoidal signal\n",
    "    s2 = np.sign(np.sin(3 * time)) + 1.1  # Signal 2: square signal\n",
    "    s3 = np.sin(2 * np.pi * time) + 1.1  # Signal 3: saw tooth signal\n",
    "    s4 = np.cos(0.5 * np.pi * time) + 1.1  # Signal 4: cosine\n",
    "    s5 = np.sin(0.2 * np.pi * time) + 1.1  # Signal 5: higher freq sine\n",
    "\n",
    "    W = np.c_[s1, s2, s3, s4, s5]\n",
    "    W += 0.1 * np.random.normal(size=W.shape)  # Add noise\n",
    "\n",
    "    W /= W.std(axis=0)  # Standardize data\n",
    "    # Mix data\n",
    "    H = np.array([[1, 1, 1, 1, 1], [0.5, 0/6, 1, 1.2, 1], [1.5, 1, 2, 1, 1.1],\n",
    "                 [1, 0.4, 1, 1.1, 0.1], [1, 0.2, 0.8, 1, 1.5]])  # Mixing matrix\n",
    "    V = np.dot(W, H.T)  # Generate observations\n",
    "    return V\n",
    "\n",
    "def test_example_V():\n",
    "    ngenes = 10\n",
    "    eg_V = example_V(ngenes)\n",
    "    # print(eg_V.shape)\n",
    "    # print(eg_V)\n",
    "    assert eg_V.shape == (10, 5)\n",
    "    assert np.all(eg_V >= 0)\n",
    "    print(\"test_example_V() passed.\")\n",
    "    \n",
    "test_example_V()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make wrapper classes for FastICA and NMF, so we can interface to them identically\n",
    "class ICA_Factorizer(FastICA):\n",
    "    def __init__(self, n_components=None, max_iter=200, \n",
    "                 random_state=42, fun='logcosh'):\n",
    "        FastICA.__init__(self, n_components=n_components, max_iter=max_iter,\n",
    "                        random_state=random_state, fun=fun)\n",
    "        self.V = None\n",
    "        self.W = None\n",
    "        self.H = None\n",
    "        self.recovered_V = None\n",
    "        \n",
    "    def fit(self, V):\n",
    "        self.V = V\n",
    "        self.W = self.fit_transform(V)\n",
    "        return self\n",
    "        \n",
    "    def get_W(self):\n",
    "        assert self.V is not None\n",
    "        if self.W is None:\n",
    "            self.W = self.fit_transform(self.V)\n",
    "        return self.W\n",
    "    \n",
    "    def get_H(self):\n",
    "        assert self.V is not None\n",
    "        if self.H is None:\n",
    "            self.H = self.mixing_.T\n",
    "        return self.H\n",
    "    \n",
    "    def get_recovered_V(self):\n",
    "        assert self.V is not None\n",
    "        if self.recovered_V is None:\n",
    "            W = self.get_W()\n",
    "            H = self.get_H()\n",
    "            mean = self.mean_\n",
    "            self.recovered_V = np.dot(W, H) + mean\n",
    "            #print(self.recovered_V)\n",
    "        return self.recovered_V\n",
    "\n",
    "def test_Factorizer(facto, atol):\n",
    "    print(facto)\n",
    "    V = example_V(10)\n",
    "    \n",
    "    facto.fit(V)\n",
    "    \n",
    "    W = facto.get_W()\n",
    "    assert W.shape == (V.shape[0], facto.n_components)\n",
    "    \n",
    "    H = facto.get_H()\n",
    "    assert H.shape == (facto.n_components, V.shape[1])\n",
    "    \n",
    "    V2 = facto.get_recovered_V()\n",
    "    assert np.allclose(V, V2, atol=atol)\n",
    "        \n",
    "    print(\"test_Factorizer (%s) passed\" % type(facto).__name__)\n",
    "    \n",
    "test_Factorizer(ICA_Factorizer(n_components=4), atol=0.5) \n",
    "test_Factorizer(ICA_Factorizer(n_components=5), atol=0.001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMF_Factorizer(NMF):\n",
    "    def __init__(self, n_components=None, max_iter=200, random_state=42):\n",
    "        NMF.__init__(self, n_components=n_components, max_iter=max_iter, \n",
    "                     random_state=random_state)\n",
    "        self.V = None\n",
    "        self.W = None\n",
    "        self.H = None\n",
    "        self.recovered_V = None\n",
    "        \n",
    "    def fit(self, V):\n",
    "        self.V = V\n",
    "        self.W = self.fit_transform(V)\n",
    "        return self\n",
    "        \n",
    "    def get_W(self):\n",
    "        assert self.V is not None\n",
    "        if self.W is None:\n",
    "            self.W = self.fit_transform(self.V)\n",
    "        return self.W\n",
    "    \n",
    "    def get_H(self):\n",
    "        assert self.V is not None\n",
    "        if self.H is None:\n",
    "            self.H = self.components_\n",
    "        return self.H\n",
    "    \n",
    "    def get_recovered_V(self):\n",
    "        assert self.V is not None\n",
    "        if self.recovered_V is None:\n",
    "            W = self.get_W()\n",
    "            H = self.get_H()\n",
    "            self.recovered_V = np.dot(W, H)\n",
    "            #print(self.recovered_V)\n",
    "        return self.recovered_V\n",
    "\n",
    "test_Factorizer(NMF_Factorizer(n_components=4), atol=1) \n",
    "test_Factorizer(NMF_Factorizer(n_components=5), atol=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA_Factorizer(PCA):\n",
    "    def __init__(self, n_components=None, max_iter=None, random_state=None):\n",
    "        PCA.__init__(self, n_components=n_components)\n",
    "        self.V = None\n",
    "        self.W = None\n",
    "        self.H = None\n",
    "        self.recovered_V = None\n",
    "        \n",
    "    def fit(self, V):\n",
    "        self.V = V\n",
    "        self.W = self.fit_transform(V)\n",
    "        return self\n",
    "        \n",
    "    def get_W(self):\n",
    "        assert self.V is not None\n",
    "        if self.W is None:\n",
    "            self.W = self.fit_transform(self.V)\n",
    "        return self.W\n",
    "    \n",
    "    def get_H(self):\n",
    "        assert self.V is not None\n",
    "        if self.H is None:\n",
    "            self.H = self.components_\n",
    "        return self.H\n",
    "    \n",
    "    def get_recovered_V(self):\n",
    "        assert self.V is not None\n",
    "        if self.recovered_V is None:\n",
    "            W = self.get_W()\n",
    "            H = self.get_H()\n",
    "            self.recovered_V = np.dot(W,H) + self.mean_\n",
    "        return self.recovered_V\n",
    "\n",
    "\n",
    "test_Factorizer(PCA_Factorizer(n_components=4), atol=1) \n",
    "test_Factorizer(PCA_Factorizer(n_components=5), atol=0.001) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix plotting utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_norm_diff(m1, m2):\n",
    "#   return np.mean(np.sqrt((m1 - m2)**2))\n",
    "    return np.sqrt(np.mean((m1 - m2)**2))\n",
    "\n",
    "def test_l2_norm_diff():\n",
    "    V = example_V(10)\n",
    "    rms = l2_norm_diff(V, V+0.5)\n",
    "    assert np.isclose(rms,0.5)\n",
    "    \n",
    "test_l2_norm_diff() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_W_H_WH_V(W, H, V, rec_V, n_genes_to_pick=None):\n",
    "    \"\"\" Show factorization matrices in visually pleasing form\"\"\"\n",
    "    \n",
    "    if n_genes_to_pick is None:\n",
    "        gene_ixs = range(V.shape[0])\n",
    "        title = \"Matrix decomposition, showing all geges\"\n",
    "    else:\n",
    "        gene_ixs = sorted(np.random.randint(0, V.shape[0], n_genes_to_pick))\n",
    "        title = \"Matrix decomposition, randomly selecting %d genes for visibility\" % n_genes_to_pick\n",
    "    fig, axs = plt.subplots(1,4, figsize=(17,6))\n",
    "    fig.suptitle(title, size=16)\n",
    "    axs[0].imshow(W[gene_ixs,:], aspect='auto')\n",
    "    axs[0].set_title('W')\n",
    "    axs[0].set_ylabel('genes', size=14)\n",
    "    axs[0].set_xlabel('factors', size=14)\n",
    "    \n",
    "    axs[0].set_xticklabels('')\n",
    "    \n",
    "    axs[1].imshow(H, aspect='auto')\n",
    "    axs[1].set_title('H')\n",
    "    axs[1].set_ylabel('factors', size=14)\n",
    "    axs[1].set_xlabel('patients', size=14)\n",
    "    axs[1].set_yticklabels('')\n",
    "    \n",
    "    rms_err = l2_norm_diff(rec_V, V)\n",
    "    axs[2].imshow(rec_V[gene_ixs,:], aspect='auto')\n",
    "    axs[2].set_title('W H (RMS err=%6.2f)' % rms_err)\n",
    "   \n",
    "    \n",
    "    axs[3].imshow(V[gene_ixs,:], aspect='auto')\n",
    "    axs[3].set_title('V')\n",
    "    axs[3].set_ylabel('genes', size=14)\n",
    "    axs[3].set_xlabel('patients', size=14)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def test_show_W_H_WH_V():\n",
    "    \n",
    "    V = example_V(10)\n",
    "    print(\"v.shape\", V.shape)\n",
    "    facto = ICA_Factorizer(n_components=2)\n",
    "    facto.fit(V)\n",
    "    W = facto.get_W()\n",
    "    H = facto.get_H()\n",
    "    print(\"H.shape\", H.shape)\n",
    "    \n",
    "    show_W_H_WH_V(W,H, V, facto.get_recovered_V())\n",
    "    show_W_H_WH_V(W,H,V, facto.get_recovered_V(), 100)\n",
    "test_show_W_H_WH_V()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and explore the expression matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in expression spreadsheet which has been processed (see end of notebook) to inlcude only protein coding genes\n",
    "expression_df = pd.read_csv('../Data/HGSOC_Protein_Expression.csv', sep='\\t')\n",
    "expression_df.set_index('GeneENSG', inplace=True)\n",
    "assert len(expression_df) == 19730   # Only \n",
    "assert len(expression_df.columns) == 80\n",
    "assert expression_df.columns[-1] == 'AOCS_171'\n",
    "\n",
    "expression_matrix = np.asarray(expression_df)\n",
    "\n",
    "print(expression_matrix.shape[0], \"genes\")\n",
    "print(expression_matrix.shape[1], \"patients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 12))\n",
    "plt.imshow(expression_matrix, aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.xlabel((\"Patients\"))\n",
    "plt.ylabel((\"Genes\"))\n",
    "plt.title(\"Expression matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a dictionary to map Ensembl ENSG ids to symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is run-once code to query for all the Ensemble gene IDs we're using, construct a dictionary and write\n",
    "# it to file.\n",
    "\n",
    "ensgDictFile = '../Cache/ensgDict.pkl'\n",
    "if not path.exists(ensgDictFile):  # Run only if dictionary file does not already exist\n",
    "    mg = mygene.MyGeneInfo()\n",
    "    ensgIDs = expression_df.index.values.tolist()    # All the gene IDs in this study\n",
    "    ginfo = mg.querymany(ensgIDs, scopes='ensembl.gene')\n",
    "\n",
    "    ensgDict = {}\n",
    "    for g in ginfo:\n",
    "        ensg = g['query']\n",
    "        del g['query'] \n",
    "        ensgDict[ensg] = g\n",
    "\n",
    "    print(\"Writing to %s...\" % ensgDictFile)\n",
    "    with open(ensgDictFile, 'wb') as f:\n",
    "        pickle.dump(ensgDict, f)\n",
    "    print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the gene dictionary file\n",
    "with open(ensgDictFile, 'rb') as f:\n",
    "    ensgDict = pickle.load(f)\n",
    "    \n",
    "for (ensg, g) in ensgDict.items():\n",
    "    if 'symbol' not in g.keys():\n",
    "        g['symbol'] = ensg    # ensure lookup always succeeds\n",
    "    \n",
    "# Example use:\n",
    "def example_ensgDict_use():\n",
    "    gid = 'ENSG00000000938'\n",
    "    # All ENSG ids used in this study should be in the dictionary\n",
    "    ginfo = ensgDict[gid]\n",
    "              \n",
    "example_ensgDict_use()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note prior normalisation of the expression array\n",
    "Normalisation was applied by Ailith's script, using the method of a varaince stabalising transform.  See below, all patients have a minimum of aproximately 3.5, maximum approaximately 23."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "expression_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot distributions of expression data\n",
    "... for a quick visual check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_expression_distributions(V):\n",
    "    def labeled_figure():\n",
    "        plt.figure(figsize=(14,4))\n",
    "        plt.xlabel('Expression level')\n",
    "        plt.ylabel('Frequency')\n",
    "        \n",
    "    if True:\n",
    "        labeled_figure()\n",
    "        _ = plt.hist(V.ravel(), bins=40)\n",
    "        plt.title(\"Distribution of all normalised expression levels\")\n",
    "        plt.show()\n",
    "    \n",
    "    if True:\n",
    "        labeled_figure()\n",
    "        _ = plt.hist(V, bins=40)\n",
    "        plt.title(\"Distribution of normalised expression levels, broken out by patient\")\n",
    "        plt.show()\n",
    "        \n",
    "    if True:\n",
    "        labeled_figure()\n",
    "        n_genes_to_pick = 100\n",
    "        random_gene_ixs = sorted(np.random.randint(0, V.shape[0], n_genes_to_pick))\n",
    "        _ = plt.hist(V[random_gene_ixs,:].T, bins=10)\n",
    "        plt.title(\"Distribution of normalised expression levels, broken out by gene, for random %d genes\" %\n",
    "                  n_genes_to_pick)\n",
    "        plt.show()\n",
    "    \n",
    "show_expression_distributions(expression_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the patient metadata\n",
    "In particular we are interested in treatment \"Resposnse\", which we scraped from the Patch paper (code at end of notebool)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read metadata (which we scraped from the Patch etal paper!)\n",
    "metadata_df = pd.read_csv('../Data/AOCS_metadata.csv', index_col='AOCS_ID')\n",
    "assert metadata_df.columns[0] == \"Age\"\n",
    "assert metadata_df.columns[1] == \"Response\"\n",
    "# Make sure the IDs match-up between the two dataframes\n",
    "assert (all(metadata_df.index == expression_df.columns))\n",
    "metadata_df['Response'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qgrid.show_grid(metadata_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use ICA, NMF and PCA factorization and plot stuff..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def fit_and_plot_model(V, met_df, facto, plot=True):\n",
    "\n",
    "    facto.fit(V)\n",
    "    W = facto.get_W()\n",
    "    H = facto.get_H()\n",
    "\n",
    "    # Show the factored matrices and compare the reconstruction with the original\n",
    "    if plot:\n",
    "        show_W_H_WH_V(W, H, V, facto.get_recovered_V(), n_genes_to_pick=200)\n",
    "    \n",
    "    plot_df = metadata_df.copy().drop('Age', axis=1)\n",
    "    \n",
    "    factors = ['Factor_%d'%i for i in range(facto.n_components)]\n",
    "    for i in range(len(factors)):\n",
    "        plot_df[factors[i]] = H[i, :]\n",
    "    \n",
    "    # Boxplots of H factors by Response\n",
    "    if plot:\n",
    "        plot_df.boxplot(column=factors, by='Response', fontsize=10, figsize=(14,4), layout=(1, facto.n_components))\n",
    "        plt.show()    \n",
    "\n",
    "    # Scatter plots of metagenes matrix - W - using Seaborne\n",
    "    if plot:\n",
    "        sns.pairplot(plot_df, hue='Response')\n",
    "        plt.show()\n",
    "        \n",
    "    # Make a t-SNE plot\n",
    "    if plot:\n",
    "        tsne = TSNE(n_components=2, init='pca', random_state=42, n_jobs=7)\n",
    "        Y = tsne.fit_transform(W)\n",
    "        sns.scatterplot(Y[:,0], Y[:,1])\n",
    "        plt.show()\n",
    "    \n",
    "    # Put together a dictionary or results\n",
    "    \n",
    "    results_dict = {}\n",
    "    \n",
    "    # Find factor which best explains response\n",
    "    \n",
    "    ols_results = [sm.ols(fact + '~ C(Response)', data=plot_df).fit() for fact in factors]\n",
    "    rsqs = [res.rsquared for res in ols_results]\n",
    "    results_dict['best_rsq'] = np.max(rsqs)\n",
    "    results_dict['best_factor'] = np.argmax(rsqs)\n",
    "    results_dict['rms_err'] = l2_norm_diff(V, facto.get_recovered_V())\n",
    "    \n",
    "    return results_dict\n",
    "\n",
    "print(\"================== ICA ======================\")\n",
    "result = fit_and_plot_model(expression_matrix, metadata_df,     \n",
    "                            ICA_Factorizer(n_components=14),\n",
    "                            plot=False)\n",
    "\n",
    "print(\"\\n================== NMF ======================\")\n",
    "result = fit_and_plot_model(expression_matrix, metadata_df,     \n",
    "                            NMF_Factorizer(n_components=14),\n",
    "                            plot=False)\n",
    "\n",
    "print(\"\\n================== PCA ======================\")\n",
    "result = fit_and_plot_model(expression_matrix, metadata_df,     \n",
    "                            PCA_Factorizer(n_components=14),\n",
    "                            plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    facto=ICA_Factorizer(n_components=14)\n",
    "    V = expression_matrix\n",
    "    facto.fit(V)\n",
    "    W = facto.get_W()\n",
    "    H = facto.get_H()\n",
    "\n",
    "    # Make a t-SNE plot\n",
    "    tsne = TSNE(n_components=2, init='pca', random_state=42, n_jobs=7)\n",
    "    Y = tsne.fit_transform(W)\n",
    "    \n",
    "    #response_dict = {'Sensitive':0, 'Refractory':1, 'Resistant':2}\n",
    "    #colour = np.array([response_dict[r] for r in plot_df['Response']]).T\n",
    "    sns.scatterplot(Y[:,0], Y[:,1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def retreive_or_generate_results1_df():\n",
    "    # Explore results for ICA, NMP and PCA, generating a list of dictionaries\n",
    "    resultsFile = '../Cache/results1.csv'\n",
    "    if not path.exists(resultsFile):\n",
    "        Factos = [ICA_Factorizer, NMF_Factorizer, PCA_Factorizer]\n",
    "        results1 = []\n",
    "        for nc in range(2,40,2):\n",
    "            for random_state in [42, 345, 13, 235, 583]:\n",
    "                for Facto in Factos:\n",
    "                    params = {'n_components':nc, 'random_state':random_state}\n",
    "\n",
    "                    facto = Facto(**params)\n",
    "                    params['which'] = type(facto).__name__\n",
    "                    print(params)\n",
    "                    res = fit_and_plot_model(expression_matrix, metadata_df, facto, plot=False)\n",
    "                    print(res)\n",
    "                    results1.append({**params, **res})\n",
    "\n",
    "        print(\"Writing results1.csv\")\n",
    "        results1_df = pd.DataFrame(results1)\n",
    "        results1_df.to_csv('results1.csv')\n",
    "        print(\"Done.\")\n",
    "\n",
    "    print(\"Reading\", resultsFile)\n",
    "    results1_df = pd.read_csv(resultsFile)\n",
    "    results1_df = results1_df.drop(columns=['Unnamed: 0'])\n",
    "    return results1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results1_df = retreive_or_generate_results1_df()\n",
    "qgrid.show_grid(results1_df)\n",
    "results1_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot rms_err vs components for each method\n",
    "results1_df = retreive_or_generate_results1_df()\n",
    "for which in [\"ICA_Factorizer\", \"NMF_Factorizer\", \"PCA_Factorizer\"]:\n",
    "    which_df = results1_df[results1_df['which']==which]\n",
    "    x,y  = which_df['n_components'], which_df['rms_err']\n",
    "    plt.plot(x,y, label=which[:3])\n",
    "plt.legend()\n",
    "plt.xlabel(\"n_components\")\n",
    "plt.ylabel(\"rms_err\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot best_rsq fit to response vs components for each method\n",
    "results1_df = retreive_or_generate_results1_df()\n",
    "for which in [\"ICA_Factorizer\", \"NMF_Factorizer\", \"PCA_Factorizer\"]:\n",
    "    which_df = results1_df[results1_df['which']==which]\n",
    "    which_df = which_df.groupby('n_components').mean()\n",
    "    x,y  = which_df.index, which_df['best_rsq']\n",
    "    plt.plot(x,y, label=which[:3])\n",
    "plt.legend()\n",
    "plt.xlabel(\"n_components\")\n",
    "plt.ylabel(\"best_rsq\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_df = results1_df[results1_df['which']==which]\n",
    "which_df.groupby('n_components').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retreive_or_generate_results2_df():\n",
    "# Explore FastICA with 14 components, for various parameters\n",
    "    resultsFile = '../Cache/results2.csv'\n",
    "    if not path.exists(resultsFile):\n",
    "        results2 = []\n",
    "        nc = 14\n",
    "        for random_state in [42, 13, 56]:\n",
    "            for max_iter in range(1, 100, 5):\n",
    "                for fun in ['logcosh'] :# , 'exp', 'cube':\n",
    "                    params = {'n_components':nc, 'random_state':random_state,\n",
    "                              'fun':fun, 'max_iter':max_iter}\n",
    "                    print(params)\n",
    "                    facto = ICA_Factorizer(**params)\n",
    "                    res = fit_and_plot_model(expression_matrix, metadata_df, facto, plot=False)\n",
    "                    print(res)\n",
    "                    results2.append({**params, **res})\n",
    "\n",
    "        print(\"Writing results2.csv\")\n",
    "        results2_df = pd.DataFrame(results2)\n",
    "        results2_df.to_csv('results2.csv')\n",
    "        print(\"Done.\")\n",
    "\n",
    "    print(\"Reading\",resultsFile)\n",
    "    results2_df = pd.read_csv(resultsFile)\n",
    "    return results2_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qgrid.show_grid(retreive_or_generate_results2_df())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring distribution of weights in W and H matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrix_weight_distributions(facto):\n",
    "    facto.fit(expression_matrix)\n",
    "    W = facto.get_W()\n",
    "    H = facto.get_H()\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.suptitle(\"Distribution of W and H matrix weights for %s\" %type(facto).__name__, size=16)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.hist(W.ravel(), bins=50, log=True)\n",
    "    plt.xlabel(\"W matrix weights\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.hist(H.ravel(), bins=20, log=True)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.xlabel(\"H matrix weights\")\n",
    "    plt.show()\n",
    "    \n",
    "facto = ICA_Factorizer(n_components=14)\n",
    "plot_matrix_weight_distributions(facto)\n",
    "\n",
    "facto = NMF_Factorizer(n_components=14)\n",
    "plot_matrix_weight_distributions(facto)\n",
    "\n",
    "facto = PCA_Factorizer(n_components=14)\n",
    "plot_matrix_weight_distributions(facto)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's find some influential genes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the k=14 metagenes matrix found by BIODICA\n",
    "\n",
    "biodica_matrix_file = \"../Factors/S_HGSOC_Protein_Expression_ica_numerical.txt_6.num\"\n",
    "biod_ica = np.loadtxt(biodica_matrix_file)\n",
    "biod_ica.shape\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "all_genes = expression_matrix.shape[0]\n",
    "n_genes = all_genes   # trim for speed while we develop\n",
    "n_comps = 6\n",
    "V = preprocessing.Normalizer().fit_transform(expression_matrix[:n_genes,:])\n",
    "\n",
    "gene_ENSG_ids = expression_df.index.values[:n_genes]\n",
    "gene_symbols = [ensgDict[ensg]['symbol'] for ensg in gene_ENSG_ids]\n",
    "nmf_facto = NMF_Factorizer(n_components=n_comps, max_iter=1000)\n",
    "ica_facto = ICA_Factorizer(n_components=n_comps)\n",
    "pca_facto = PCA_Factorizer(n_components=n_comps)\n",
    "\n",
    "nmf_facto.fit(V)\n",
    "print(\"NMF fit done\")\n",
    "ica_facto.fit(V)\n",
    "print(\"ICA fit done\")\n",
    "pca_facto.fit(V)\n",
    "print(\"PCA fit done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_component_ranked_plots(metagene_matrix):\n",
    "    assert metagene_matrix.shape == (n_genes, n_comps)\n",
    "    fig = plt.figure(figsize=(14,14))\n",
    "\n",
    "    for ci in range(n_comps):\n",
    "        plt.subplot(4,4,ci+1)\n",
    "        metagene = metagene_matrix[:, ci]\n",
    "        #influence = abs(metagene)\n",
    "        influence = metagene\n",
    "        gixpairs = zip(gene_symbols, influence)\n",
    "        gixpairs = sorted(gixpairs, key=lambda p: -p[1])\n",
    "        ranked_symbols, ranked_influence,  = zip(*gixpairs)\n",
    "        plt.plot(ranked_influence)\n",
    "        plt.yscale('log')\n",
    "        if ci == 0:\n",
    "            plt.xlabel('Influence rank')\n",
    "            plt.ylabel('Influence')\n",
    "        fig.tight_layout() \n",
    "        plt.title('Component %d' % ci)\n",
    "    plt.show()    \n",
    "\n",
    "\n",
    "show_component_ranked_plots(abs(biod_ica))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_component_distributions(metagene_matrix):\n",
    "    assert metagene_matrix.shape == (n_genes, n_comps)\n",
    "    fig = plt.figure(figsize=(14,14))\n",
    "\n",
    "    for ci in range(n_comps):\n",
    "        plt.subplot(4,4,ci+1)\n",
    "        metagene = metagene_matrix[:, ci]\n",
    "        #influence = abs(metagene)\n",
    "        influence = metagene\n",
    "        \n",
    "        plt.hist(influence, bins=20)\n",
    "        plt.yscale('log')\n",
    "        if ci == 0:\n",
    "            plt.xlabel('Freq')\n",
    "            plt.ylabel('Influence')\n",
    "        fig.tight_layout() \n",
    "        plt.title('Component %d' % ci)\n",
    "    plt.show()    \n",
    "\n",
    "show_component_distributions(abs(biod_ica))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def gene_enrichment_analysis(metagene, top_n):\n",
    "    influence = abs(metagene)\n",
    "    # influence = metagene\n",
    "    gixpairs = zip(gene_symbols, influence)\n",
    "    gixpairs = sorted(gixpairs, key=lambda p: -p[1])\n",
    "    ranked_symbols, ranked_influence,  = zip(*gixpairs)\n",
    "    return ranked_symbols[:top_n]\n",
    "        \n",
    "\n",
    "# W = abs(biod_ica)\n",
    "W = biod_ica\n",
    "for ci in range(n_comps):\n",
    "    genes = gene_enrichment_analysis(W[:,ci], 20)\n",
    "    if False:\n",
    "        print(\"Comp. %d: %s\" % (ci, ' '.join(genes)))\n",
    "    else:\n",
    "        print(\"Comp. %d: \\n%s\\n\" % (ci, '\\n'.join(genes)))\n",
    "        # print(\"Comp. %d: \\n%s\\n\" % (ci, genes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Following is run-once code for recovering metadata from the Patch et al paper..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract age and response group from scraped text file\n",
    "def extract_metadata_from_crazy_scraped_file(scrape_file):\n",
    "    with open(scrape_file, 'r') as f:\n",
    "        l1 = f.readline().strip()\n",
    "        l2 = f.readline().strip()\n",
    "    l1_words = l1.split(' ')\n",
    "    aocs_ids = l1_words[::2]\n",
    "    aocs_ids = [s.replace('-','_') for s in aocs_ids]\n",
    "    \n",
    "    ages = l1_words[1::2]\n",
    "    response = l2.split(' ')\n",
    "    assert len(aocs_ids) == len(ages) == len(response) == 80\n",
    "    # Build a dataframe\n",
    "    df = pd.DataFrame()\n",
    "    df['AOCS_ID'] = aocs_ids\n",
    "    df['Age'] = ages\n",
    "    df['Response'] = response\n",
    "    \n",
    "    df = df.set_index('AOCS_ID')\n",
    "    df = df.sort_index()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable only if 'AOCS_metadata.csv' is to be re-created\n",
    "if False:\n",
    "    metadata_df = extract_metadata_from_crazy_scraped_file('../Data/aocs_raw_figure_e6.txt')\n",
    "    metadata_df.to_csv('../Data/AOCS_metadata.csv')\n",
    "    readback_metadata_df = pd.read_csv('../Data/AOCS_metadata.csv', index_col='AOCS_ID')\n",
    "    readback_metadata_df\n",
    "    assert len(readback_metadata_df) == 80\n",
    "    readback_metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run-once code to convert create a protein coding gene only expression file\n",
    "\n",
    "The original 'AOCS_TPM_VST.csv' contains 57,424 transcripts, many of which are non-codeing.   We wish to work with protein coding genes only.  We proceed as follows:\n",
    "1. Read AOCS_TPM_VST.csv into a dataframe with ENSG identifiers as index\n",
    "1. Write a text file listing all ENSG identifiers extracted from AOCS_TPM_VST.csv creating ensg_list.txt\n",
    "1. Obtain an annotated gene table from [Biomart](https://m.ensembl.org/info/data/biomart/index.html):\n",
    "   1. Manually (should automate) upload ensg_list.txt\n",
    "   1. Select attributes of Gene stable ID, Gene name, Gene type, and Gene description; it's Gene type which is important\n",
    "   1. Export the generated table to 'DownloadedResources/mart_export.txt'\n",
    "1. Read mart_export.txt into a dataframe with ENSG identifiers as index and filter on Gene type == 'protein_coding'\n",
    "1. Merge the original full expression dataframe with the filtered dataframe\n",
    "1. Write out a tab-seperated file 'HGSOC_Protein_Expression.csv' containing GeneENSG as first column with patient expression values in the following 80 columns\n",
    "\n",
    "The generated HGSOC_Protein_Expression.csv is in a format suitable for direct input to BIODICA and can be used for all other analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    # Read in original full AOCS spreadsheet\n",
    "    full_expression_df = pd.read_csv('../Data/AOCS_TPM_VST.csv')\n",
    "    full_expression_df.set_index('GeneENSG', inplace=True)\n",
    "    assert len(full_expression_df) == 57914\n",
    "    assert len(full_expression_df.columns == 80 + 1)\n",
    "    assert full_expression_df.columns[-1] == 'AOCS_171'\n",
    "    ensglist = full_expression_df.index.values.tolist()\n",
    "    with open('../Cache/ensg_list.txt', 'w') as f:\n",
    "        f.write('\\n'.join(ensglist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where you have to do the manual Biomart stuff as described above... then run the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    # Read in the Biomart created file\n",
    "    mart_export_df = pd.read_csv('../DownloadedResources/mart_export.txt', sep='\\t')\n",
    "    mart_export_df.set_index('Gene stable ID', inplace=True)\n",
    "    assert mart_export_df.loc['ENSG00000198804', 'Gene type'] == 'protein_coding'\n",
    "    \n",
    "    # Create a dataframe containing only protein coding genes\n",
    "    mart_export_protein_coding_df = mart_export_df[mart_export_df['Gene type'] == 'protein_coding']\n",
    "\n",
    "    # Merge with full expression dataframe (only those present in both will be kept)\n",
    "    expression_protein_coding_df = pd.merge(\n",
    "        left=full_expression_df, right=mart_export_protein_coding_df, \n",
    "        left_index=True, right_index=True)\n",
    "    expression_protein_coding_df.drop(columns=['Gene name', 'Gene type', 'Gene description'], inplace=True)\n",
    "    assert len(expression_protein_coding_df.columns) == 80\n",
    "\n",
    "    # Write the filtered expression matrix to a .csv file\n",
    "    expression_protein_coding_df.to_csv('../Data/HGSOC_Protein_Expression.csv', index=True, index_label='GeneENSG', sep='\\t')\n",
    "    \n",
    "    # Read it back and check all in order\n",
    "    del expression_protein_coding_df\n",
    "    expression_protein_coding_df = pd.read_csv('../Data/HGSOC_Protein_Expression.csv', sep='\\t')\n",
    "    expression_protein_coding_df.set_index('GeneENSG', inplace=True)\n",
    "    assert len(expression_protein_coding_df.columns) == 80\n",
    "    assert len(expression_protein_coding_df) == 19730\n",
    "    \n",
    "    # Paranoia: the following specific expression value was manually extracted from the orginal AOCS_TPM_VST.csv,\n",
    "    # and is compared here to check we haven't somehow scrambled the ordering anywhere!\n",
    "    assert expression_protein_coding_df.loc['ENSG00000138772', 'AOCS_004'] == 12.6329098049671\n",
    "    \n",
    "    del full_expression_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
