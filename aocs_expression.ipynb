{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying ICA / NMF to AOCS Ovarian Cancer gene expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import NMF, FastICA, PCA\n",
    "import statsmodels.formula.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "import ipysheet\n",
    "import qgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_V(n_genes=100):\n",
    "    # Generate example expression matrix, useful in tests\n",
    "    np.random.seed(0)\n",
    "    time = np.linspace(0, 8, n_genes)\n",
    "\n",
    "    s1 = np.sin(time) + 1.1  # Signal 1 : sinusoidal signal\n",
    "    s2 = np.sign(np.sin(3 * time)) + 1.1  # Signal 2: square signal\n",
    "    s3 = np.sin(2 * np.pi * time) + 1.1  # Signal 3: saw tooth signal\n",
    "    s4 = np.cos(0.5 * np.pi * time) + 1.1  # Signal 4: cosine\n",
    "    s5 = np.sin(0.2 * np.pi * time) + 1.1  # Signal 5: higher freq sine\n",
    "\n",
    "    W = np.c_[s1, s2, s3, s4, s5]\n",
    "    W += 0.1 * np.random.normal(size=W.shape)  # Add noise\n",
    "\n",
    "    W /= W.std(axis=0)  # Standardize data\n",
    "    # Mix data\n",
    "    H = np.array([[1, 1, 1, 1, 1], [0.5, 0/6, 1, 1.2, 1], [1.5, 1, 2, 1, 1.1],\n",
    "                 [1, 0.4, 1, 1.1, 0.1], [1, 0.2, 0.8, 1, 1.5]])  # Mixing matrix\n",
    "    V = np.dot(W, H.T)  # Generate observations\n",
    "    return V\n",
    "\n",
    "def test_example_V():\n",
    "    ngenes = 10\n",
    "    eg_V = example_V(ngenes)\n",
    "    print(eg_V.shape)\n",
    "    print(eg_V)\n",
    "    assert eg_V.shape == (10, 5)\n",
    "    assert np.all(eg_V >= 0)\n",
    "test_example_V()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make wrapper classes for FastICA and NMF, so we can interface to them identically\n",
    "class ICA_Factorizer(FastICA):\n",
    "    def __init__(self, n_components=None, max_iter=200, \n",
    "                 random_state=42, fun='logcosh'):\n",
    "        FastICA.__init__(self, n_components=n_components, max_iter=max_iter,\n",
    "                        random_state=random_state, fun=fun)\n",
    "        self.V = None\n",
    "        self.W = None\n",
    "        self.H = None\n",
    "        self.recovered_V = None\n",
    "        \n",
    "    def fit(self, V):\n",
    "        self.V = V\n",
    "        self.W = self.fit_transform(V)\n",
    "        \n",
    "    def get_W(self):\n",
    "        assert self.V is not None\n",
    "        if self.W is None:\n",
    "            self.W = self.fit_transform(self.V)\n",
    "        return self.W\n",
    "    \n",
    "    def get_H(self):\n",
    "        assert self.V is not None\n",
    "        if self.H is None:\n",
    "            self.H = self.mixing_.T\n",
    "        return self.H\n",
    "    \n",
    "    def get_recovered_V(self):\n",
    "        assert self.V is not None\n",
    "        if self.recovered_V is None:\n",
    "            W = self.get_W()\n",
    "            H = self.get_H()\n",
    "            mean = self.mean_\n",
    "            self.recovered_V = np.dot(W, H) + mean\n",
    "            #print(self.recovered_V)\n",
    "        return self.recovered_V\n",
    "\n",
    "def test_Factorizer(facto, atol):\n",
    "    print(facto)\n",
    "    V = example_V(10)\n",
    "    nc = V.shape[1]\n",
    "    \n",
    "    facto.fit(V)\n",
    "    \n",
    "    W = facto.get_W()\n",
    "    assert W.shape == (V.shape[0], nc)\n",
    "    \n",
    "    H = facto.get_H()\n",
    "    assert H.shape == (nc, V.shape[1])\n",
    "    \n",
    "    V2 = facto.get_recovered_V()\n",
    "    assert np.allclose(V, V2, atol=atol)\n",
    "        \n",
    "    print(\"test_Factorizer (%s) passed\" % type(facto).__name__)\n",
    "    \n",
    "test_Factorizer(ICA_Factorizer(n_components=5), atol=0.0001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMF_Factorizer(NMF):\n",
    "    def __init__(self, n_components=None, max_iter=200, random_state=42):\n",
    "        NMF.__init__(self, n_components=n_components, max_iter=max_iter, \n",
    "                     random_state=random_state)\n",
    "        self.V = None\n",
    "        self.W = None\n",
    "        self.H = None\n",
    "        self.recovered_V = None\n",
    "        \n",
    "    def fit(self, V):\n",
    "        self.V = V\n",
    "        self.W = self.fit_transform(V)\n",
    "        \n",
    "    def get_W(self):\n",
    "        assert self.V is not None\n",
    "        if self.W is None:\n",
    "            self.W = self.fit_transform(self.V)\n",
    "        return self.W\n",
    "    \n",
    "    def get_H(self):\n",
    "        assert self.V is not None\n",
    "        if self.H is None:\n",
    "            self.H = self.components_\n",
    "        return self.H\n",
    "    \n",
    "    def get_recovered_V(self):\n",
    "        assert self.V is not None\n",
    "        if self.recovered_V is None:\n",
    "            W = self.get_W()\n",
    "            H = self.get_H()\n",
    "            self.recovered_V = np.dot(W, H)\n",
    "            #print(self.recovered_V)\n",
    "        return self.recovered_V\n",
    "\n",
    "test_Factorizer(NMF_Factorizer(n_components=5), atol=0.2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix plotting utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_norm_diff(m1, m2):\n",
    "    return np.mean(np.sqrt((m1 - m2)**2))\n",
    "\n",
    "def test_l2_norm_diff():\n",
    "    V = example_V(10)\n",
    "    rms = l2_norm_diff(V, V+0.5)\n",
    "    assert np.isclose(rms,0.5)\n",
    "    \n",
    "test_l2_norm_diff() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_W_H_WH_V(W, H, V, rec_V, n_genes_to_pick=None):\n",
    "    \"\"\" Show factorization matrices in visually pleasing form\"\"\"\n",
    "    \n",
    "    if n_genes_to_pick is None:\n",
    "        gene_ixs = range(V.shape[0])\n",
    "        title = \"Matrix decomposition, showing all geges\"\n",
    "    else:\n",
    "        gene_ixs = sorted(np.random.randint(0, V.shape[0], n_genes_to_pick))\n",
    "        title = \"Matrix decomposition, randomly selecting %d genes for visibility\" % n_genes_to_pick\n",
    "    fig, axs = plt.subplots(1,4, figsize=(17,6))\n",
    "    fig.suptitle(title, size=16)\n",
    "    axs[0].imshow(W[gene_ixs,:], aspect='auto')\n",
    "    axs[0].set_title('W')\n",
    "    axs[0].set_ylabel('genes', size=14)\n",
    "    axs[0].set_xlabel('factors', size=14)\n",
    "    \n",
    "    axs[0].set_xticklabels('')\n",
    "    \n",
    "    axs[1].imshow(H, aspect='auto')\n",
    "    axs[1].set_title('H')\n",
    "    axs[1].set_ylabel('factors', size=14)\n",
    "    axs[1].set_xlabel('patients', size=14)\n",
    "    axs[1].set_yticklabels('')\n",
    "    \n",
    "    rms_err = l2_norm_diff(rec_V, V)\n",
    "    axs[2].imshow(rec_V[gene_ixs,:], aspect='auto')\n",
    "    axs[2].set_title('W H (RMS err=%6.2f)' % rms_err)\n",
    "   \n",
    "    \n",
    "    axs[3].imshow(V[gene_ixs,:], aspect='auto')\n",
    "    axs[3].set_title('V')\n",
    "    axs[3].set_ylabel('genes', size=14)\n",
    "    axs[3].set_xlabel('patients', size=14)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def test_show_W_H_WH_V():\n",
    "    \n",
    "    V = example_V(10)\n",
    "    print(\"v.shape\", V.shape)\n",
    "    facto = ICA_Factorizer(n_components=2)\n",
    "    facto.fit(V)\n",
    "    W = facto.get_W()\n",
    "    H = facto.get_H()\n",
    "    print(\"H.shape\", H.shape)\n",
    "    \n",
    "    show_W_H_WH_V(W,H, V, facto.get_recovered_V())\n",
    "    show_W_H_WH_V(W,H,V, facto.get_recovered_V(), 100)\n",
    "test_show_W_H_WH_V()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and explore the expression matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in AOCS spreadsheet\n",
    "expression_df = pd.read_csv('AOCS_TPM_VST.csv')\n",
    "\n",
    "assert len(expression_df) == 57914\n",
    "assert len(expression_df.columns == 80 + 1)\n",
    "assert expression_df.columns[0] == 'GeneENSG'\n",
    "assert expression_df.columns[-1] == 'AOCS_171'\n",
    "\n",
    "expression_matrix = np.asarray(expression_df.iloc[:,1:])\n",
    "\n",
    "print(expression_matrix.shape[0], \"genes\")\n",
    "print(expression_matrix.shape[1], \"patients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 12))\n",
    "plt.imshow(expression_matrix, aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.xlabel((\"Patients\"))\n",
    "plt.ylabel((\"Genes\"))\n",
    "plt.title(\"Expression matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note prior normalisation of the expression array\n",
    "Normalisation was applied by Ailith's script, using the method of a varaince stabalising transform.  See below, all patients have a minimum of aproximately 3.5, maximum approaximately 23."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "expression_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot distributions of expression data\n",
    "... for a quick visual check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_expression_distributions(V):\n",
    "    def labeled_figure():\n",
    "        plt.figure(figsize=(14,4))\n",
    "        plt.xlabel('Expression level')\n",
    "        plt.ylabel('Frequency')\n",
    "        \n",
    "    if True:\n",
    "        labeled_figure()\n",
    "        _ = plt.hist(V.ravel(), bins=40)\n",
    "        plt.title(\"Distribution of all normalised expression levels\")\n",
    "        plt.show()\n",
    "    \n",
    "    if True:\n",
    "        labeled_figure()\n",
    "        _ = plt.hist(V, bins=40)\n",
    "        plt.title(\"Distribution of normalised expression levels, broken out by patient\")\n",
    "        plt.show()\n",
    "        \n",
    "    if True:\n",
    "        labeled_figure()\n",
    "        n_genes_to_pick = 100\n",
    "        random_gene_ixs = sorted(np.random.randint(0, V.shape[0], n_genes_to_pick))\n",
    "        _ = plt.hist(V[random_gene_ixs,:].T, bins=10)\n",
    "        plt.title(\"Distribution of normalised expression levels, broken out by gene, for random %d genes\" %\n",
    "                  n_genes_to_pick)\n",
    "        plt.show()\n",
    "    \n",
    "show_expression_distributions(expression_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the patient metadata\n",
    "In particular we are interested in treatment \"Resposnse\", which we scraped from the Patch paper (code at end of notebool)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read metadata (which we scraped from the Patch etal paper!)\n",
    "metadata_df = pd.read_csv('AOCS_metadata.csv', index_col='AOCS_ID')\n",
    "assert metadata_df.columns[0] == \"Age\"\n",
    "assert metadata_df.columns[1] == \"Response\"\n",
    "# Make sure the IDs match-up between the two dataframes\n",
    "assert (all(metadata_df.index == expression_df.columns[1:]))\n",
    "metadata_df['Response'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qgrid.show_grid(metadata_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def fit_and_plot_model(V, met_df, facto, plot=True):\n",
    "    # print(\"---------------------------------------------------------------------------\")\n",
    "    # print(facto)\n",
    "\n",
    "    facto.fit(V)\n",
    "    W = facto.get_W()\n",
    "    H = facto.get_H()\n",
    "\n",
    "    # Show the factored matrices and compare the reconstruction with the original\n",
    "    if False:\n",
    "        show_W_H_WH_V(W, H, V, facto.get_recovered_V(), n_genes_to_pick=200)\n",
    "    \n",
    "    plot_df = metadata_df.copy()\n",
    "    \n",
    "    factors = ['Factor_%d'%i for i in range(facto.n_components)]\n",
    "    for i in range(len(factors)):\n",
    "        plot_df[factors[i]] = H[i, :]\n",
    "    \n",
    "    # Boxplots of H factors by Response\n",
    "    if False:\n",
    "        plot_df.boxplot(column=factors, by='Response', fontsize=10, figsize=(12,4), layout=(1, facto.n_components))\n",
    "        plt.show()    \n",
    "        \n",
    "    # Scatter plot of metagenes matrix - W\n",
    "    if plot:\n",
    "        k = W.shape[1]\n",
    "        plt.figure(figsize=(k*4,4))\n",
    "        for i in range(0, k):\n",
    "            plt.subplot(1,k,i+1)\n",
    "            plt.scatter(W[:,i-1], W[:,i], s=0.5)\n",
    "            plt.xlabel(\"Factor %d\" % (i-1))\n",
    "            plt.ylabel(\"Factor %d\" % i)\n",
    "        plt.suptitle(\"Scatter plots of W matrix - 'metagenes'\")\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize=(k*4,4))\n",
    "        for i in range(0, k):\n",
    "            plt.subplot(1,k,i+1)\n",
    "            plt.scatter(H[i-1, :], H[i, :])\n",
    "            plt.xlabel(\"Factor %d\" % (i-1))\n",
    "            plt.ylabel(\"Factor %d\" % i)\n",
    "        plt.suptitle(\"Scatter plots of H matrix - 'metasamples'\")\n",
    "        plt.show()\n",
    "            \n",
    "    \n",
    "    # Put together a dictionary or results\n",
    "    results_dict = {}\n",
    "    \n",
    "    # Find factor which best explains response\n",
    "    \n",
    "    ols_results = [sm.ols(fact + '~ C(Response)', data=plot_df).fit() for fact in factors]\n",
    "    rsqs = [res.rsquared for res in ols_results]\n",
    "    results_dict['best_rsq'] = np.max(rsqs)\n",
    "    results_dict['best_factor'] = np.argmax(rsqs)\n",
    "    results_dict['rms_err'] = l2_norm_diff(V, facto.get_recovered_V())\n",
    "    \n",
    "    return results_dict\n",
    "\n",
    "print(\"================== ICA ======================\")\n",
    "result = fit_and_plot_model(expression_matrix, metadata_df,     \n",
    "                            ICA_Factorizer(n_components=4),\n",
    "                            plot=True)\n",
    "\n",
    "print(\"\\n================== NMF ======================\")\n",
    "result = fit_and_plot_model(expression_matrix, metadata_df,     \n",
    "                            NMF_Factorizer(n_components=4),\n",
    "                            plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Explore results for NMF and ICA, generating a list of dictionaries\n",
    "results1 = None\n",
    "if False:\n",
    "    Factos = [ICA_Factorizer, NMF_Factorizer]\n",
    "    results1 = []\n",
    "    for nc in range(1,7):\n",
    "        for random_state in [42, 345, 13]:\n",
    "            for Facto in Factos:\n",
    "                params = {'n_components':nc, 'random_state':random_state}\n",
    "                \n",
    "                facto = Facto(**params)\n",
    "                params['which'] = type(facto).__name__\n",
    "                print(params)\n",
    "                res = fit_and_plot_model(expression_matrix, metadata_df, facto, plot=False)\n",
    "                print(res)\n",
    "                results1.append({**params, **res})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results1:\n",
    "    results1_df = pd.DataFrame(results1)\n",
    "    qgrid.show_grid(results1_df)\n",
    "    results1_df.to_csv('nmf_ica_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore FastICA with 5 components, for various parameterss\n",
    "\n",
    "results2 = None\n",
    "if False:\n",
    "    results2 = []\n",
    "    nc = 5\n",
    "    for random_state in [42, 13, 56]:\n",
    "        for max_iter in range(1, 100, 5):\n",
    "            for fun in ['logcosh'] :# , 'exp', 'cube':\n",
    "                params = {'n_components':nc, 'random_state':random_state,\n",
    "                          'fun':fun, 'max_iter':max_iter}\n",
    "                print(params)\n",
    "                facto = ICA_Factorizer(**params)\n",
    "                res = fit_and_plot_model(expression_matrix, metadata_df, facto, plot=False)\n",
    "                print(res)\n",
    "                results2.append({**params, **res})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if results2 is not None:\n",
    "    print(\"Hello\")\n",
    "    results2_df = pd.DataFrame(results2)\n",
    "    results2_df.to_csv('ica_fun_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qgrid.show_grid(results2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(results2_df['max_iter'], results2_df['best_rsq'], s=0.6)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring distribution of weights in W and H matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrix_weight_distributions(facto):\n",
    "    facto.fit(expression_matrix)\n",
    "    W = facto.get_W()\n",
    "    H = facto.get_H()\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.suptitle(\"Distribution of W and H matrix weights for %s\" %type(facto).__name__, size=16)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.hist(W.ravel(), bins=50, log=True)\n",
    "    plt.xlabel(\"W matrix weights\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.hist(H.ravel(), bins=20, log=True)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.xlabel(\"H matrix weights\")\n",
    "    plt.show()\n",
    "    \n",
    "facto = ICA_Factorizer(n_components=5)\n",
    "plot_matrix_weight_distributions(facto)\n",
    "\n",
    "facto = NMF_Factorizer(n_components=5)\n",
    "plot_matrix_weight_distributions(facto)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Following is run-once code for recovering metadata from Patch et al paper..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "* Five components seems to be best for both ICA and NMF w.r.t Response correlation with Response. \n",
    "* ICA delivers sligntly better $R^2$ for correlation.  With 5 components $R^2$ = 0.145 and 0.363 for ICA and NMF respectively.\n",
    "* RMS error improves with number of components, as expected, but only modestly -- 0.499 to 0.403 for 1 to 6 components.\n",
    "* RMS error between W H and V is almost constant at 0.416 with 5 components, regardless of algorithm ICA / NMF choice or other hyper-parameters.\n",
    "* NMF seems immune to random effects (random seeds).\n",
    "* ICA shows modest random effects, in respect of the $R^2$ measure.\n",
    "* ICA shows identical results for max_iter in range 100 - 5000; suggests the default 200 can safely be used.\n",
    "* The optimised functional in ICA, among the options of logcosh, exp and cube have less effect than the random seed.   Some suggestion that the default logcosh is marginally optimal, exp is worst.\n",
    "* NMF delivers W and H matrices such that W.H = V.  This is not quite the case for ICA, due to whitening.   For ICA we need W.H + mean = V.\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract age and response group from scraped text file\n",
    "def extract_metadata_from_crazy_scraped_file(scrape_file):\n",
    "    with open(scrape_file, 'r') as f:\n",
    "        l1 = f.readline().strip()\n",
    "        l2 = f.readline().strip()\n",
    "    l1_words = l1.split(' ')\n",
    "    aocs_ids = l1_words[::2]\n",
    "    aocs_ids = [s.replace('-','_') for s in aocs_ids]\n",
    "    \n",
    "    ages = l1_words[1::2]\n",
    "    response = l2.split(' ')\n",
    "    assert len(aocs_ids) == len(ages) == len(response) == 80\n",
    "    # Build a dataframe\n",
    "    df = pd.DataFrame()\n",
    "    df['AOCS_ID'] = aocs_ids\n",
    "    df['Age'] = ages\n",
    "    df['Response'] = response\n",
    "    \n",
    "    df = df.set_index('AOCS_ID')\n",
    "    df = df.sort_index()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable only if 'AOCS_metadata.csv' is to be re-created\n",
    "if False:\n",
    "    metadata_df = extract_metadata_from_crazy_scraped_file('aocs_raw_figure_e6.txt')\n",
    "    metadata_df.to_csv('AOCS_metadata.csv')\n",
    "    readback_metadata_df = pd.read_csv('AOCS_metadata.csv', index_col='AOCS_ID')\n",
    "    readback_metadata_df\n",
    "    assert len(readback_metadata_df) == 80\n",
    "    readback_metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
